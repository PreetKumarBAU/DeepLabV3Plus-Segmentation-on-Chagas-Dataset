{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "deeplabv3-plus.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-09-14T10:52:57.992466Z",
          "iopub.execute_input": "2021-09-14T10:52:57.992830Z",
          "iopub.status.idle": "2021-09-14T10:52:57.998641Z",
          "shell.execute_reply.started": "2021-09-14T10:52:57.992799Z",
          "shell.execute_reply": "2021-09-14T10:52:57.997667Z"
        },
        "trusted": true,
        "id": "PNfpi6Q0jXrM"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n",
        "    add, multiply\n",
        "from keras.layers import concatenate, core, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.core import Lambda\n",
        "#import keras.backend as K\n",
        "\n",
        "#%tensorflow_version 1.x\n",
        "import os\n",
        "import keras\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "#import keras.backend.tensorflow_backend as K\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import CSVLogger\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T10:52:58.003912Z",
          "iopub.execute_input": "2021-09-14T10:52:58.004217Z",
          "iopub.status.idle": "2021-09-14T10:52:58.010295Z",
          "shell.execute_reply.started": "2021-09-14T10:52:58.004184Z",
          "shell.execute_reply": "2021-09-14T10:52:58.009388Z"
        },
        "trusted": true,
        "id": "2a8AfzPOjXrQ"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T10:52:58.012071Z",
          "iopub.execute_input": "2021-09-14T10:52:58.012434Z",
          "iopub.status.idle": "2021-09-14T10:52:58.048393Z",
          "shell.execute_reply.started": "2021-09-14T10:52:58.012398Z",
          "shell.execute_reply": "2021-09-14T10:52:58.047578Z"
        },
        "trusted": true,
        "id": "iTf8lIwLjXrS"
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "import numpy as np\n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import cv2\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "BackGround = [255, 255, 255]\n",
        "road = [0, 0, 0]\n",
        "# COLOR_DICT = np.array([BackGround, road])\n",
        "one = [128, 128, 128]\n",
        "two = [128, 0, 0]\n",
        "three = [192, 192, 128]\n",
        "four = [255, 69, 0]\n",
        "five = [128, 64, 128]\n",
        "six = [60, 40, 222]\n",
        "seven = [128, 128, 0]\n",
        "eight = [192, 128, 128]\n",
        "nine = [64, 64, 128]\n",
        "ten = [64, 0, 128]\n",
        "eleven = [64, 64, 0]\n",
        "twelve = [0, 128, 192]\n",
        "COLOR_DICT = np.array([one, two,three,four,five,six,seven,eight,nine,ten,eleven,twelve])\n",
        "\n",
        "\n",
        "class data_preprocess:\n",
        "    def __init__(self, train_path=None, image_folder=None, label_folder=None,\n",
        "                 valid_path=None,valid_image_folder =None,valid_label_folder = None,\n",
        "                 test_path=None, save_path=None,\n",
        "                 img_rows=256, img_cols=256,\n",
        "                 flag_multi_class=False,\n",
        "                 num_classes = 2):\n",
        "        self.img_rows = img_rows\n",
        "        self.img_cols = img_cols\n",
        "        self.train_path = train_path\n",
        "        self.image_folder = image_folder\n",
        "        self.label_folder = label_folder\n",
        "        self.valid_path = valid_path\n",
        "        self.valid_image_folder = valid_image_folder\n",
        "        self.valid_label_folder = valid_label_folder\n",
        "        self.test_path = test_path\n",
        "        self.save_path = save_path\n",
        "        self.data_gen_args = dict(rotation_range=20,\n",
        "                                  width_shift_range=0.002,\n",
        "                                  shear_range=0.03,\n",
        "                                  zoom_range=0.005,\n",
        "                                  vertical_flip=True,\n",
        "                                  horizontal_flip=True,\n",
        "                                  fill_mode='nearest')\n",
        "        self.image_color_mode = \"rgb\"\n",
        "        self.label_color_mode = \"grayscale\"\n",
        "\n",
        "        self.flag_multi_class = flag_multi_class\n",
        "        self.num_class = num_classes\n",
        "        self.target_size = (256, 256)\n",
        "        self.img_type = 'png'\n",
        "\n",
        "    def adjustData(self, img, label):\n",
        "        if (self.flag_multi_class):\n",
        "            img = img / 255.\n",
        "            label = label[:, :, :, 0] if (len(label.shape) == 4) else label[:, :, 0]\n",
        "            new_label = np.zeros(label.shape + (self.num_class,))\n",
        "            for i in range(self.num_class):\n",
        "                new_label[label == i, i] = 1\n",
        "            label = new_label\n",
        "        elif (np.max(img) > 1):\n",
        "            #img = img / 255.\n",
        "            #label = label / 255.\n",
        "            #label[label >= 0.5] = 1\n",
        "            #label[label < 0.5] = 0\n",
        "            img2 =np.asarray(img)\n",
        "            label2 =np.asarray(label)\n",
        "            img2 =img2.astype('float32')\n",
        "            label2 =label2.astype('float32')\n",
        "            img2 /= 255.0\n",
        "            label2 /= 255.0\n",
        "            label2[label2 >= 0.5] = 1\n",
        "            label2[label2 < 0.5] = 0\n",
        "        return (img2, label2)\n",
        "\n",
        "    def trainGenerator(self, batch_size, image_save_prefix=\"image\", label_save_prefix=\"label\",\n",
        "                       save_to_dir=None, seed=7):\n",
        "        '''\n",
        "        can generate image and label at the same time\n",
        "        use the same seed for image_datagen and label_datagen to ensure the transformation for image and label is the same\n",
        "        if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "        '''\n",
        "        image_datagen = ImageDataGenerator(**self.data_gen_args)\n",
        "        label_datagen = ImageDataGenerator(**self.data_gen_args)\n",
        "        image_generator = image_datagen.flow_from_directory(\n",
        "            self.train_path,\n",
        "            classes=[self.image_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.image_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            save_to_dir=save_to_dir,\n",
        "            save_prefix=image_save_prefix,\n",
        "            seed=seed)\n",
        "        label_generator = label_datagen.flow_from_directory(\n",
        "            self.train_path,\n",
        "            classes=[self.label_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.label_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            save_to_dir=save_to_dir,\n",
        "            save_prefix=label_save_prefix,\n",
        "            seed=seed)\n",
        "        train_generator = zip(image_generator, label_generator)\n",
        "        for (img, label) in train_generator:\n",
        "            img, label = self.adjustData(img, label)\n",
        "            yield (img, label)\n",
        "\n",
        "    def testGenerator(self):\n",
        "        filenames = os.listdir(self.test_path)\n",
        "        for filename in filenames:\n",
        "            img = io.imread(os.path.join(self.test_path, filename), as_gray=False)\n",
        "            img = img / 255.\n",
        "            img = trans.resize(img, self.target_size, mode='constant')\n",
        "            img = np.reshape(img, img.shape + (1,)) if (not self.flag_multi_class) else img\n",
        "            img = np.reshape(img, (1,) + img.shape)\n",
        "            yield img\n",
        "\n",
        "    def validLoad(self, batch_size,seed=7):\n",
        "        image_datagen = ImageDataGenerator(rescale=0)\n",
        "        label_datagen = ImageDataGenerator(rescale=0)\n",
        "        image_generator = image_datagen.flow_from_directory(\n",
        "            self.valid_path,\n",
        "            classes=[self.valid_image_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.image_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            seed=seed)\n",
        "        label_generator = label_datagen.flow_from_directory(\n",
        "            self.valid_path,\n",
        "            classes=[self.valid_label_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.label_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            seed=seed)\n",
        "        train_generator = zip(image_generator, label_generator)\n",
        "        for (img, label) in train_generator:\n",
        "            img, label = self.adjustData(img, label)\n",
        "            yield (img, label)\n",
        "        # return imgs,labels\n",
        "\n",
        "    def saveResult(self, npyfile, size, name,threshold=80):\n",
        "        for i, item in enumerate(npyfile):\n",
        "            img = item\n",
        "            img_std = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
        "            if self.flag_multi_class:\n",
        "                for row in range(len(img)):\n",
        "                    for col in range(len(img[row])):\n",
        "                        num = np.argmax(img[row][col])\n",
        "                        img_std[row][col] = COLOR_DICT[num]\n",
        "            else:\n",
        "                for k in range(len(img)):\n",
        "                    for j in range(len(img[k])):\n",
        "                        num = img[k][j]\n",
        "                        if num < (threshold/255.0):\n",
        "                            img_std[k][j] = road\n",
        "                        else:\n",
        "                            img_std[k][j] = BackGround\n",
        "            img_std = cv2.resize(img_std, size, interpolation=cv2.INTER_CUBIC)\n",
        "            cv2.imwrite(os.path.join(self.save_path, (\"%s_predict.\" + self.img_type) % (name)), img_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T10:52:58.131645Z",
          "iopub.execute_input": "2021-09-14T10:52:58.131937Z",
          "iopub.status.idle": "2021-09-14T10:52:58.155303Z",
          "shell.execute_reply.started": "2021-09-14T10:52:58.131912Z",
          "shell.execute_reply": "2021-09-14T10:52:58.154317Z"
        },
        "trusted": true,
        "id": "VVdzJaSWjXra"
      },
      "source": [
        "####  Metrics\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "def dice_coeff(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss\n",
        "def iou_coeff(y_true, y_pred):\n",
        "    smooth=1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union=K.sum(y_true_f) + K.sum(y_pred_f)-intersection\n",
        "    mvalue=(intersection+smooth)/(union+smooth)\n",
        "    return mvalue\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "def ACL5(y_true, y_pred): \n",
        "\n",
        "\t#y_pred = K.cast(y_pred, dtype = 'float64')\n",
        "\n",
        "\tprint(K.int_shape(y_pred))\n",
        "\n",
        "\tx = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:] # horizontal and vertical directions \n",
        "\ty = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n",
        "\n",
        "\tdelta_x = x[:,1:,:-2,:]**2\n",
        "\tdelta_y = y[:,:-2,1:,:]**2\n",
        "\tdelta_u = K.abs(delta_x + delta_y) \n",
        "\n",
        "\tepsilon = 0.00000001 # where is a parameter to avoid square root is zero in practice.\n",
        "\tw = 1####\n",
        "\tlenth = w * K.sum(K.sqrt(delta_u + epsilon)) # equ.(11) in the paper\n",
        "\n",
        "\n",
        "\tC_1 = np.ones((256, 256))\n",
        "\tC_2 = np.zeros((256, 256))\n",
        "\n",
        "\tregion_in = K.abs(K.sum( y_pred[:,:,:,0] * ((y_true[:,:,:,0] - C_1)**2) ) ) # equ.(12) in the paper\n",
        "\tregion_out = K.abs(K.sum( (1-y_pred[:,:,:,0]) * ((y_true[:,:,:,0] - C_2)**2) )) # equ.(12) in the paper\n",
        "\n",
        "\tlambdaP = 5 # lambda parameter could be various.\n",
        "\t\n",
        "\tloss =  lenth + lambdaP * ((region_in) + (region_out)) \n",
        "\n",
        "\treturn loss\n",
        "def ACL5_mod(y_true, y_pred): \n",
        "\n",
        "\t#y_pred = K.cast(y_pred, dtype = 'float64')\n",
        "\n",
        "\tprint(K.int_shape(y_pred))\n",
        "\n",
        "\tx = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:] # horizontal and vertical directions \n",
        "\ty = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n",
        "\n",
        "\tdelta_x = x[:,1:,:-2,:]**2\n",
        "\tdelta_y = y[:,:-2,1:,:]**2\n",
        "\tdelta_u = K.abs(delta_x + delta_y) \n",
        "\n",
        "\tepsilon = 0.00000001 # where is a parameter to avoid square root is zero in practice.\n",
        "\tw = 1####\n",
        "\tlenth = w * K.sum(K.sqrt(delta_u + epsilon)) # equ.(11) in the paper\n",
        "\n",
        "\n",
        "\tC_1 = np.ones((256, 256))\n",
        "\tC_2 = np.zeros((256, 256))\n",
        "\n",
        "\tregion_in = K.abs(K.sum( y_pred[:,:,:,0] * ((y_true[:,:,:,0] - C_1)**2) ) ) # equ.(12) in the paper\n",
        "\tregion_out = K.abs(K.sum( (1-y_pred[:,:,:,0]) * ((y_true[:,:,:,0] - C_2)**2) )) # equ.(12) in the paper\n",
        "\n",
        "\tlambdaP = 5 # lambda parameter could be various.\n",
        "\t\n",
        "\tloss =  lenth + lambdaP * ((region_in) + (region_out*1.4)) \n",
        "\n",
        "\treturn loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwu9rjDFjXrd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T10:52:58.156761Z",
          "iopub.execute_input": "2021-09-14T10:52:58.157243Z",
          "iopub.status.idle": "2021-09-14T10:52:58.168616Z",
          "shell.execute_reply.started": "2021-09-14T10:52:58.157195Z",
          "shell.execute_reply": "2021-09-14T10:52:58.167721Z"
        },
        "trusted": true,
        "id": "-YuW43lejXrd"
      },
      "source": [
        "beta = 0.25\n",
        "alpha = 0.25\n",
        "gamma = 2\n",
        "epsilon = 1e-5\n",
        "smooth = 1\n",
        "\n",
        "def tversky_index( y_true, y_pred):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
        "    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (\n",
        "                1 - alpha) * false_pos + smooth)\n",
        "\n",
        "def tversky_loss( y_true, y_pred):\n",
        "    return 1 - tversky_index(y_true, y_pred)\n",
        "\n",
        "def focal_tversky( y_true, y_pred):\n",
        "    pt_1 = tversky_index(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1 - pt_1), gamma)\n",
        "\n",
        "def dsc(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dsc(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T10:52:58.171185Z",
          "iopub.execute_input": "2021-09-14T10:52:58.172553Z",
          "iopub.status.idle": "2021-09-14T10:52:58.181807Z",
          "shell.execute_reply.started": "2021-09-14T10:52:58.172519Z",
          "shell.execute_reply": "2021-09-14T10:52:58.180864Z"
        },
        "trusted": true,
        "id": "kr5nP8ItjXre",
        "outputId": "48e77d7c-c144-4f17-e726-e4b36dce7171"
      },
      "source": [
        "%env SM_FRAMEWORK=tf.keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "env: SM_FRAMEWORK=tf.keras\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T10:52:58.183223Z",
          "iopub.execute_input": "2021-09-14T10:52:58.183506Z",
          "iopub.status.idle": "2021-09-14T10:53:04.596311Z",
          "shell.execute_reply.started": "2021-09-14T10:52:58.183465Z",
          "shell.execute_reply": "2021-09-14T10:53:04.595284Z"
        },
        "trusted": true,
        "id": "KMTFbTKtjXrf",
        "outputId": "2bd1e0fe-2f4f-479d-e8e6-b255673c5ad3"
      },
      "source": [
        "!pip install segmentation_models\n",
        "import segmentation_models\n",
        "from segmentation_models.losses import bce_jaccard_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: segmentation_models in /opt/conda/lib/python3.7/site-packages (1.0.1)\nRequirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from segmentation_models) (1.0.8)\nRequirement already satisfied: image-classifiers==1.0.0 in /opt/conda/lib/python3.7/site-packages (from segmentation_models) (1.0.0)\nRequirement already satisfied: efficientnet==1.0.0 in /opt/conda/lib/python3.7/site-packages (from segmentation_models) (1.0.0)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation_models) (0.18.2)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.10.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.19.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.15.0)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.4.2)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.9.0)\nRequirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.6.3)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.7.2)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (8.2.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.7)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.1)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (5.0.9)\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T10:53:04.599052Z",
          "iopub.execute_input": "2021-09-14T10:53:04.599436Z",
          "iopub.status.idle": "2021-09-14T10:53:04.604771Z",
          "shell.execute_reply.started": "2021-09-14T10:53:04.599393Z",
          "shell.execute_reply": "2021-09-14T10:53:04.603617Z"
        },
        "trusted": true,
        "id": "IVcpwi4hjXrg"
      },
      "source": [
        "def ACL5_bce_jaccard_loss(y_true, y_pred):\n",
        "    loss = ACL5(y_true, y_pred) + bce_jaccard_loss(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def focal_tversky_bce_jaccard_loss(y_true, y_pred):\n",
        "    loss = focal_tversky(y_true, y_pred) + 2*bce_jaccard_loss(y_true, y_pred)\n",
        "    return loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T10:53:04.605993Z",
          "iopub.execute_input": "2021-09-14T10:53:04.606459Z",
          "iopub.status.idle": "2021-09-14T10:53:04.615421Z",
          "shell.execute_reply.started": "2021-09-14T10:53:04.606413Z",
          "shell.execute_reply": "2021-09-14T10:53:04.614671Z"
        },
        "trusted": true,
        "id": "eDJ9CtzQjXrh"
      },
      "source": [
        "\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.layers import Conv2D , BatchNormalization , Activation , MaxPool2D , Input , Dropout , ZeroPadding2D , Conv2DTranspose , Concatenate\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.applications import InceptionResNetV2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccYNxPZwjXri"
      },
      "source": [
        "# DeepLabV3Plus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU-bbp33jXrj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T10:53:04.616866Z",
          "iopub.execute_input": "2021-09-14T10:53:04.617309Z",
          "iopub.status.idle": "2021-09-14T10:53:06.209318Z",
          "shell.execute_reply.started": "2021-09-14T10:53:04.617272Z",
          "shell.execute_reply": "2021-09-14T10:53:06.203569Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "kFchkooujXrk",
        "outputId": "cc29d1b8-4e58-475a-baab-26468e90c067"
      },
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, UpSampling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "\"\"\" Atrous Spatial Pyramid Pooling \"\"\"\n",
        "def ASPP(inputs):\n",
        "    shape = inputs.shape\n",
        "\n",
        "    y_pool = AveragePooling2D(pool_size=(shape[1], shape[2]), name='average_pooling')(inputs)\n",
        "    y_pool = Conv2D(filters=256, kernel_size=1, padding='same', use_bias=False)(y_pool)\n",
        "    y_pool = BatchNormalization(name=f'bn_1')(y_pool)\n",
        "    y_pool = Activation('relu', name=f'relu_1')(y_pool)\n",
        "    y_pool = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y_pool)\n",
        "\n",
        "    y_1 = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(inputs)\n",
        "    y_1 = BatchNormalization()(y_1)\n",
        "    y_1 = Activation('relu')(y_1)\n",
        "\n",
        "    y_6 = Conv2D(filters=256, kernel_size=3, dilation_rate=6, padding='same', use_bias=False)(inputs)\n",
        "    y_6 = BatchNormalization()(y_6)\n",
        "    y_6 = Activation('relu')(y_6)\n",
        "\n",
        "    y_12 = Conv2D(filters=256, kernel_size=3, dilation_rate=12, padding='same', use_bias=False)(inputs)\n",
        "    y_12 = BatchNormalization()(y_12)\n",
        "    y_12 = Activation('relu')(y_12)\n",
        "\n",
        "    y_18 = Conv2D(filters=256, kernel_size=3, dilation_rate=18, padding='same', use_bias=False)(inputs)\n",
        "    y_18 = BatchNormalization()(y_18)\n",
        "    y_18 = Activation('relu')(y_18)\n",
        "\n",
        "    y = Concatenate()([y_pool, y_1, y_6, y_12, y_18])\n",
        "\n",
        "    y = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    return y\n",
        "\n",
        "def DeepLabV3Plus(shape):\n",
        "    \"\"\" Inputs \"\"\"\n",
        "    inputs = Input(shape)\n",
        "\n",
        "    \"\"\" Pre-trained ResNet50 \"\"\"\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "\n",
        "    \"\"\" Pre-trained ResNet50 Output \"\"\"\n",
        "    image_features = base_model.get_layer('conv4_block6_out').output\n",
        "    x_a = ASPP(image_features)\n",
        "    x_a = UpSampling2D((4, 4), interpolation=\"bilinear\")(x_a)\n",
        "\n",
        "    \"\"\" Get low-level features \"\"\"\n",
        "    x_b = base_model.get_layer('conv2_block2_out').output\n",
        "    x_b = Conv2D(filters=48, kernel_size=1, padding='same', use_bias=False)(x_b)\n",
        "    x_b = BatchNormalization()(x_b)\n",
        "    x_b = Activation('relu')(x_b)\n",
        "\n",
        "    x = Concatenate()([x_a, x_b])\n",
        "\n",
        "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = UpSampling2D((4, 4), interpolation=\"bilinear\")(x)\n",
        "\n",
        "    \"\"\" Outputs \"\"\"\n",
        "    x = Conv2D(2, kernel_size=(3, 3),activation='relu', padding='same', strides=(1, 1))(x)\n",
        "    x = Conv2D(1, (1, 1), name='output_layer')(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "\n",
        "    \"\"\" Model \"\"\"\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    return model\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_2[0][0]                    \n__________________________________________________________________________________________________\nconv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n__________________________________________________________________________________________________\nconv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n__________________________________________________________________________________________________\npool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n__________________________________________________________________________________________________\npool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n                                                                 conv2_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n                                                                 conv2_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n                                                                 conv2_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n                                                                 conv3_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n                                                                 conv3_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n                                                                 conv3_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n                                                                 conv3_block4_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n                                                                 conv4_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n                                                                 conv4_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n                                                                 conv4_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n                                                                 conv4_block4_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n                                                                 conv4_block5_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n                                                                 conv4_block6_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n__________________________________________________________________________________________________\naverage_pooling (AveragePooling (None, 1, 1, 1024)   0           conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 1, 1, 256)    262144      average_pooling[0][0]            \n__________________________________________________________________________________________________\nbn_1 (BatchNormalization)       (None, 1, 1, 256)    1024        conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 16, 16, 256)  262144      conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 16, 16, 256)  2359296     conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 16, 16, 256)  2359296     conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 16, 16, 256)  2359296     conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nrelu_1 (Activation)             (None, 1, 1, 256)    0           bn_1[0][0]                       \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 16, 16, 256)  1024        conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 16, 16, 256)  1024        conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 16, 16, 256)  1024        conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_3 (UpSampling2D)  (None, 16, 16, 256)  0           relu_1[0][0]                     \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 16, 16, 256)  0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 16, 16, 256)  0           batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 16, 16, 256)  0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 16, 16, 256)  0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 16, 16, 1280) 0           up_sampling2d_3[0][0]            \n                                                                 activation_9[0][0]               \n                                                                 activation_10[0][0]              \n                                                                 activation_11[0][0]              \n                                                                 activation_12[0][0]              \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 16, 16, 256)  327680      concatenate_2[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 16, 16, 256)  1024        conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 64, 64, 48)   12288       conv2_block2_out[0][0]           \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 16, 16, 256)  0           batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 64, 64, 48)   192         conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_4 (UpSampling2D)  (None, 64, 64, 256)  0           activation_13[0][0]              \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 64, 64, 48)   0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 64, 64, 304)  0           up_sampling2d_4[0][0]            \n                                                                 activation_14[0][0]              \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 64, 64, 256)  700416      concatenate_3[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 64, 64, 256)  1024        conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 64, 64, 256)  0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 64, 64, 256)  589824      activation_15[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 64, 64, 256)  1024        conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 64, 64, 256)  0           batch_normalization_15[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_5 (UpSampling2D)  (None, 256, 256, 256 0           activation_16[0][0]              \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 256, 256, 2)  4610        up_sampling2d_5[0][0]            \n__________________________________________________________________________________________________\noutput_layer (Conv2D)           (None, 256, 256, 1)  3           conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 256, 256, 1)  0           output_layer[0][0]               \n==================================================================================================\nTotal params: 17,834,565\nTrainable params: 17,799,781\nNon-trainable params: 34,784\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T11:00:23.329478Z",
          "iopub.execute_input": "2021-09-14T11:00:23.329901Z",
          "iopub.status.idle": "2021-09-14T11:00:25.177903Z",
          "shell.execute_reply.started": "2021-09-14T11:00:23.329867Z",
          "shell.execute_reply": "2021-09-14T11:00:25.177076Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "z73b0ddqjXrl",
        "outputId": "a89c753e-139b-4b08-a496-19df793d5048"
      },
      "source": [
        "   \n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "#path to images\n",
        "train_path = \"../input/training/training\"\n",
        "image_folder = \"images\"\n",
        "label_folder = \"label\"\n",
        "valid_path =  \"../input/validation/Validation\"\n",
        "valid_image_folder =\"images\"\n",
        "valid_label_folder = \"label\"\n",
        "log_filepath = './log'\n",
        "flag_multi_class = False\n",
        "num_classes = 2\n",
        "dp = data_preprocess(train_path=train_path,image_folder=image_folder,label_folder=label_folder,\n",
        "                     valid_path=valid_path,valid_image_folder=valid_image_folder,valid_label_folder=valid_label_folder,\n",
        "                     flag_multi_class=flag_multi_class,\n",
        "                     num_classes=num_classes)\n",
        "\n",
        "train_data = dp.trainGenerator(batch_size=2)\n",
        "valid_data = dp.validLoad(batch_size=1)\n",
        "test_data = dp.testGenerator()\n",
        "lrate = 7.00E-05 \n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, Multiply, AveragePooling2D, UpSampling2D\n",
        "if __name__ == \"__main__\":\n",
        "    input_shape = (256, 256, 3)\n",
        "    model = DeepLabV3Plus(input_shape)\n",
        "    model.summary()\n",
        "    model_checkpoint1 = keras.callbacks.ModelCheckpoint('Res2Net.hdf5', monitor='val_dice_loss',verbose=1,mode='min',save_best_only=True)\n",
        "    csv_logger = CSVLogger('trainingRes2Net.log', append=True, separator=';')\n",
        "    model.compile(optimizer=Adam(lr=lrate), loss=ACL5, metrics=[ACL5 ,bce_jaccard_loss ,  dice_loss,iou_coeff,precision,recall])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_4[0][0]                    \n__________________________________________________________________________________________________\nconv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n__________________________________________________________________________________________________\nconv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n__________________________________________________________________________________________________\npool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n__________________________________________________________________________________________________\npool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n                                                                 conv2_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n                                                                 conv2_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n                                                                 conv2_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n                                                                 conv3_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n                                                                 conv3_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n                                                                 conv3_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n                                                                 conv3_block4_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n                                                                 conv4_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n                                                                 conv4_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n                                                                 conv4_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n                                                                 conv4_block4_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n                                                                 conv4_block5_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n                                                                 conv4_block6_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n__________________________________________________________________________________________________\naverage_pooling (AveragePooling (None, 1, 1, 1024)   0           conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv2d_30 (Conv2D)              (None, 1, 1, 256)    262144      average_pooling[0][0]            \n__________________________________________________________________________________________________\nbn_1 (BatchNormalization)       (None, 1, 1, 256)    1024        conv2d_30[0][0]                  \n__________________________________________________________________________________________________\nconv2d_31 (Conv2D)              (None, 16, 16, 256)  262144      conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv2d_32 (Conv2D)              (None, 16, 16, 256)  2359296     conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv2d_33 (Conv2D)              (None, 16, 16, 256)  2359296     conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv2d_34 (Conv2D)              (None, 16, 16, 256)  2359296     conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nrelu_1 (Activation)             (None, 1, 1, 256)    0           bn_1[0][0]                       \n__________________________________________________________________________________________________\nbatch_normalization_24 (BatchNo (None, 16, 16, 256)  1024        conv2d_31[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_25 (BatchNo (None, 16, 16, 256)  1024        conv2d_32[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_26 (BatchNo (None, 16, 16, 256)  1024        conv2d_33[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_27 (BatchNo (None, 16, 16, 256)  1024        conv2d_34[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_9 (UpSampling2D)  (None, 16, 16, 256)  0           relu_1[0][0]                     \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 16, 16, 256)  0           batch_normalization_24[0][0]     \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 16, 16, 256)  0           batch_normalization_25[0][0]     \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 16, 16, 256)  0           batch_normalization_26[0][0]     \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 16, 16, 256)  0           batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nconcatenate_6 (Concatenate)     (None, 16, 16, 1280) 0           up_sampling2d_9[0][0]            \n                                                                 activation_27[0][0]              \n                                                                 activation_28[0][0]              \n                                                                 activation_29[0][0]              \n                                                                 activation_30[0][0]              \n__________________________________________________________________________________________________\nconv2d_35 (Conv2D)              (None, 16, 16, 256)  327680      concatenate_6[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_28 (BatchNo (None, 16, 16, 256)  1024        conv2d_35[0][0]                  \n__________________________________________________________________________________________________\nconv2d_36 (Conv2D)              (None, 64, 64, 48)   12288       conv2_block2_out[0][0]           \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 16, 16, 256)  0           batch_normalization_28[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_29 (BatchNo (None, 64, 64, 48)   192         conv2d_36[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_10 (UpSampling2D) (None, 64, 64, 256)  0           activation_31[0][0]              \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 64, 64, 48)   0           batch_normalization_29[0][0]     \n__________________________________________________________________________________________________\nconcatenate_7 (Concatenate)     (None, 64, 64, 304)  0           up_sampling2d_10[0][0]           \n                                                                 activation_32[0][0]              \n__________________________________________________________________________________________________\nconv2d_37 (Conv2D)              (None, 64, 64, 256)  700416      concatenate_7[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_30 (BatchNo (None, 64, 64, 256)  1024        conv2d_37[0][0]                  \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 64, 64, 256)  0           batch_normalization_30[0][0]     \n__________________________________________________________________________________________________\nconv2d_38 (Conv2D)              (None, 64, 64, 256)  589824      activation_33[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_31 (BatchNo (None, 64, 64, 256)  1024        conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 64, 64, 256)  0           batch_normalization_31[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_11 (UpSampling2D) (None, 256, 256, 256 0           activation_34[0][0]              \n__________________________________________________________________________________________________\nconv2d_39 (Conv2D)              (None, 256, 256, 2)  4610        up_sampling2d_11[0][0]           \n__________________________________________________________________________________________________\noutput_layer (Conv2D)           (None, 256, 256, 1)  3           conv2d_39[0][0]                  \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 256, 256, 1)  0           output_layer[0][0]               \n==================================================================================================\nTotal params: 17,834,565\nTrainable params: 17,799,781\nNon-trainable params: 34,784\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T11:00:38.243187Z",
          "iopub.execute_input": "2021-09-14T11:00:38.243540Z",
          "iopub.status.idle": "2021-09-14T13:04:16.592265Z",
          "shell.execute_reply.started": "2021-09-14T11:00:38.243487Z",
          "shell.execute_reply": "2021-09-14T13:04:16.591237Z"
        },
        "trusted": true,
        "id": "DJLOnaYejXrm",
        "outputId": "deabad6b-2cf2-449a-8124-ea3bd1e2a072"
      },
      "source": [
        "history = model.fit_generator(train_data,\n",
        "                              steps_per_epoch=1912,epochs=40,\n",
        "                              validation_steps=207,\n",
        "                              validation_data=valid_data,\n",
        "                              callbacks=[model_checkpoint1,csv_logger])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Found 600 images belonging to 1 classes.\nFound 600 images belonging to 1 classes.\nEpoch 1/40\n(None, 256, 256, 1)\n(None, 256, 256, 1)\n(None, 256, 256, 1)\n(None, 256, 256, 1)\n1912/1912 [==============================] - ETA: 0s - loss: 27080.3408 - ACL5: 27080.3408 - binary_crossentropy_plus_jaccard_loss: 0.7235 - dice_loss: 0.5298 - iou_coeff: 0.3464 - precision: 0.7203 - recall: 0.5315Found 200 images belonging to 1 classes.\nFound 200 images belonging to 1 classes.\n(None, 256, 256, 1)\n(None, 256, 256, 1)\n1912/1912 [==============================] - 213s 105ms/step - loss: 27071.3953 - ACL5: 27071.3953 - binary_crossentropy_plus_jaccard_loss: 0.7235 - dice_loss: 0.5297 - iou_coeff: 0.3464 - precision: 0.7204 - recall: 0.5315 - val_loss: 2383.7427 - val_ACL5: 2383.7427 - val_binary_crossentropy_plus_jaccard_loss: 0.5423 - val_dice_loss: 0.3775 - val_iou_coeff: 0.5051 - val_precision: 0.7824 - val_recall: 0.5528\n\nEpoch 00001: val_dice_loss improved from inf to 0.37748, saving model to Res2Net.hdf5\nEpoch 2/40\n1912/1912 [==============================] - 183s 96ms/step - loss: 3877.3110 - ACL5: 3877.3110 - binary_crossentropy_plus_jaccard_loss: 0.3830 - dice_loss: 0.2199 - iou_coeff: 0.6481 - precision: 0.8565 - recall: 0.7442 - val_loss: 2196.3953 - val_ACL5: 2196.3953 - val_binary_crossentropy_plus_jaccard_loss: 0.5012 - val_dice_loss: 0.3468 - val_iou_coeff: 0.5437 - val_precision: 0.7741 - val_recall: 0.5901\n\nEpoch 00002: val_dice_loss improved from 0.37748 to 0.34677, saving model to Res2Net.hdf5\nEpoch 3/40\n1912/1912 [==============================] - 184s 96ms/step - loss: 3489.3299 - ACL5: 3489.3299 - binary_crossentropy_plus_jaccard_loss: 0.3518 - dice_loss: 0.1980 - iou_coeff: 0.6815 - precision: 0.8585 - recall: 0.7694 - val_loss: 2103.9875 - val_ACL5: 2103.9875 - val_binary_crossentropy_plus_jaccard_loss: 0.5002 - val_dice_loss: 0.3417 - val_iou_coeff: 0.5592 - val_precision: 0.7502 - val_recall: 0.6064\n\nEpoch 00003: val_dice_loss improved from 0.34677 to 0.34172, saving model to Res2Net.hdf5\nEpoch 4/40\n1912/1912 [==============================] - 183s 96ms/step - loss: 3373.9702 - ACL5: 3373.9702 - binary_crossentropy_plus_jaccard_loss: 0.3403 - dice_loss: 0.1839 - iou_coeff: 0.6974 - precision: 0.8651 - recall: 0.7866 - val_loss: 2615.5281 - val_ACL5: 2615.5281 - val_binary_crossentropy_plus_jaccard_loss: 0.5586 - val_dice_loss: 0.4040 - val_iou_coeff: 0.4915 - val_precision: 0.7453 - val_recall: 0.5405\n\nEpoch 00004: val_dice_loss did not improve from 0.34172\nEpoch 5/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 3239.5672 - ACL5: 3239.5672 - binary_crossentropy_plus_jaccard_loss: 0.3330 - dice_loss: 0.1770 - iou_coeff: 0.7086 - precision: 0.8662 - recall: 0.7949 - val_loss: 1865.9760 - val_ACL5: 1865.9760 - val_binary_crossentropy_plus_jaccard_loss: 0.4308 - val_dice_loss: 0.2444 - val_iou_coeff: 0.6545 - val_precision: 0.7812 - val_recall: 0.6987\n\nEpoch 00005: val_dice_loss improved from 0.34172 to 0.24439, saving model to Res2Net.hdf5\nEpoch 6/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 3101.8356 - ACL5: 3101.8356 - binary_crossentropy_plus_jaccard_loss: 0.3187 - dice_loss: 0.1647 - iou_coeff: 0.7252 - precision: 0.8728 - recall: 0.8101 - val_loss: 1795.3419 - val_ACL5: 1795.3419 - val_binary_crossentropy_plus_jaccard_loss: 0.4135 - val_dice_loss: 0.2249 - val_iou_coeff: 0.6718 - val_precision: 0.8196 - val_recall: 0.7010\n\nEpoch 00006: val_dice_loss improved from 0.24439 to 0.22487, saving model to Res2Net.hdf5\nEpoch 7/40\n1912/1912 [==============================] - 184s 96ms/step - loss: 3040.1891 - ACL5: 3040.1891 - binary_crossentropy_plus_jaccard_loss: 0.3182 - dice_loss: 0.1606 - iou_coeff: 0.7300 - precision: 0.8773 - recall: 0.8127 - val_loss: 1899.5878 - val_ACL5: 1899.5878 - val_binary_crossentropy_plus_jaccard_loss: 0.4685 - val_dice_loss: 0.2671 - val_iou_coeff: 0.6333 - val_precision: 0.7706 - val_recall: 0.6628\n\nEpoch 00007: val_dice_loss did not improve from 0.22487\nEpoch 8/40\n1912/1912 [==============================] - 186s 97ms/step - loss: 2970.1051 - ACL5: 2970.1051 - binary_crossentropy_plus_jaccard_loss: 0.3153 - dice_loss: 0.1566 - iou_coeff: 0.7362 - precision: 0.8766 - recall: 0.8201 - val_loss: 2391.9207 - val_ACL5: 2391.9207 - val_binary_crossentropy_plus_jaccard_loss: 0.5389 - val_dice_loss: 0.3616 - val_iou_coeff: 0.5386 - val_precision: 0.7553 - val_recall: 0.5847\n\nEpoch 00008: val_dice_loss did not improve from 0.22487\nEpoch 9/40\n1912/1912 [==============================] - 186s 97ms/step - loss: 2885.7525 - ACL5: 2885.7525 - binary_crossentropy_plus_jaccard_loss: 0.3057 - dice_loss: 0.1494 - iou_coeff: 0.7460 - precision: 0.8823 - recall: 0.8274 - val_loss: 1816.2686 - val_ACL5: 1816.2686 - val_binary_crossentropy_plus_jaccard_loss: 0.4422 - val_dice_loss: 0.2778 - val_iou_coeff: 0.6199 - val_precision: 0.7801 - val_recall: 0.6793\n\nEpoch 00009: val_dice_loss did not improve from 0.22487\nEpoch 10/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 2823.3495 - ACL5: 2823.3495 - binary_crossentropy_plus_jaccard_loss: 0.3045 - dice_loss: 0.1458 - iou_coeff: 0.7509 - precision: 0.8851 - recall: 0.8293 - val_loss: 1850.4890 - val_ACL5: 1850.4890 - val_binary_crossentropy_plus_jaccard_loss: 0.4403 - val_dice_loss: 0.2260 - val_iou_coeff: 0.6711 - val_precision: 0.7937 - val_recall: 0.7066\n\nEpoch 00010: val_dice_loss did not improve from 0.22487\nEpoch 11/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 2792.5075 - ACL5: 2792.5075 - binary_crossentropy_plus_jaccard_loss: 0.3040 - dice_loss: 0.1446 - iou_coeff: 0.7539 - precision: 0.8833 - recall: 0.8312 - val_loss: 1739.2200 - val_ACL5: 1739.2200 - val_binary_crossentropy_plus_jaccard_loss: 0.4137 - val_dice_loss: 0.2057 - val_iou_coeff: 0.6919 - val_precision: 0.8073 - val_recall: 0.7248\n\nEpoch 00011: val_dice_loss improved from 0.22487 to 0.20574, saving model to Res2Net.hdf5\nEpoch 12/40\n1912/1912 [==============================] - 186s 97ms/step - loss: 2742.6971 - ACL5: 2742.6971 - binary_crossentropy_plus_jaccard_loss: 0.3000 - dice_loss: 0.1395 - iou_coeff: 0.7607 - precision: 0.8858 - recall: 0.8339 - val_loss: 2076.8621 - val_ACL5: 2076.8621 - val_binary_crossentropy_plus_jaccard_loss: 0.4918 - val_dice_loss: 0.3095 - val_iou_coeff: 0.5796 - val_precision: 0.8034 - val_recall: 0.6420\n\nEpoch 00012: val_dice_loss did not improve from 0.20574\nEpoch 13/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 2739.2011 - ACL5: 2739.2011 - binary_crossentropy_plus_jaccard_loss: 0.2984 - dice_loss: 0.1396 - iou_coeff: 0.7600 - precision: 0.8923 - recall: 0.8365 - val_loss: 1836.2295 - val_ACL5: 1836.2295 - val_binary_crossentropy_plus_jaccard_loss: 0.4295 - val_dice_loss: 0.2246 - val_iou_coeff: 0.6668 - val_precision: 0.8277 - val_recall: 0.7157\n\nEpoch 00013: val_dice_loss did not improve from 0.20574\nEpoch 14/40\n1912/1912 [==============================] - 186s 97ms/step - loss: 2663.6537 - ACL5: 2663.6537 - binary_crossentropy_plus_jaccard_loss: 0.2949 - dice_loss: 0.1375 - iou_coeff: 0.7644 - precision: 0.8901 - recall: 0.8394 - val_loss: 1877.1282 - val_ACL5: 1877.1282 - val_binary_crossentropy_plus_jaccard_loss: 0.4610 - val_dice_loss: 0.2375 - val_iou_coeff: 0.6611 - val_precision: 0.7743 - val_recall: 0.6941\n\nEpoch 00014: val_dice_loss did not improve from 0.20574\nEpoch 15/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 2580.9512 - ACL5: 2580.9512 - binary_crossentropy_plus_jaccard_loss: 0.2834 - dice_loss: 0.1284 - iou_coeff: 0.7767 - precision: 0.8959 - recall: 0.8481 - val_loss: 1856.7046 - val_ACL5: 1856.7046 - val_binary_crossentropy_plus_jaccard_loss: 0.4693 - val_dice_loss: 0.2432 - val_iou_coeff: 0.6516 - val_precision: 0.7949 - val_recall: 0.6658\n\nEpoch 00015: val_dice_loss did not improve from 0.20574\nEpoch 16/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 2549.9405 - ACL5: 2549.9405 - binary_crossentropy_plus_jaccard_loss: 0.2777 - dice_loss: 0.1275 - iou_coeff: 0.7789 - precision: 0.8962 - recall: 0.8522 - val_loss: 1727.4713 - val_ACL5: 1727.4713 - val_binary_crossentropy_plus_jaccard_loss: 0.4101 - val_dice_loss: 0.2039 - val_iou_coeff: 0.6918 - val_precision: 0.7962 - val_recall: 0.7651\n\nEpoch 00016: val_dice_loss improved from 0.20574 to 0.20387, saving model to Res2Net.hdf5\nEpoch 17/40\n1912/1912 [==============================] - 186s 97ms/step - loss: 2518.4042 - ACL5: 2518.4042 - binary_crossentropy_plus_jaccard_loss: 0.2778 - dice_loss: 0.1258 - iou_coeff: 0.7814 - precision: 0.8970 - recall: 0.8531 - val_loss: 1915.3730 - val_ACL5: 1915.3730 - val_binary_crossentropy_plus_jaccard_loss: 0.4613 - val_dice_loss: 0.2366 - val_iou_coeff: 0.6576 - val_precision: 0.7996 - val_recall: 0.6972\n\nEpoch 00017: val_dice_loss did not improve from 0.20387\nEpoch 18/40\n1912/1912 [==============================] - 186s 97ms/step - loss: 2527.8284 - ACL5: 2527.8284 - binary_crossentropy_plus_jaccard_loss: 0.2788 - dice_loss: 0.1257 - iou_coeff: 0.7808 - precision: 0.8994 - recall: 0.8546 - val_loss: 1633.7323 - val_ACL5: 1633.7323 - val_binary_crossentropy_plus_jaccard_loss: 0.4169 - val_dice_loss: 0.2047 - val_iou_coeff: 0.6938 - val_precision: 0.7972 - val_recall: 0.7388\n\nEpoch 00018: val_dice_loss did not improve from 0.20387\nEpoch 19/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 2403.9115 - ACL5: 2403.9115 - binary_crossentropy_plus_jaccard_loss: 0.2686 - dice_loss: 0.1208 - iou_coeff: 0.7898 - precision: 0.9022 - recall: 0.8565 - val_loss: 1897.0127 - val_ACL5: 1897.0127 - val_binary_crossentropy_plus_jaccard_loss: 0.4427 - val_dice_loss: 0.2181 - val_iou_coeff: 0.6785 - val_precision: 0.8070 - val_recall: 0.7338\n\nEpoch 00019: val_dice_loss did not improve from 0.20387\nEpoch 20/40\n1912/1912 [==============================] - 186s 97ms/step - loss: 2385.6869 - ACL5: 2385.6869 - binary_crossentropy_plus_jaccard_loss: 0.2620 - dice_loss: 0.1197 - iou_coeff: 0.7924 - precision: 0.9034 - recall: 0.8604 - val_loss: 1932.4082 - val_ACL5: 1932.4082 - val_binary_crossentropy_plus_jaccard_loss: 0.4981 - val_dice_loss: 0.2647 - val_iou_coeff: 0.6299 - val_precision: 0.7932 - val_recall: 0.6496\n\nEpoch 00020: val_dice_loss did not improve from 0.20387\nEpoch 21/40\n1912/1912 [==============================] - 184s 96ms/step - loss: 2398.9040 - ACL5: 2398.9040 - binary_crossentropy_plus_jaccard_loss: 0.2658 - dice_loss: 0.1201 - iou_coeff: 0.7916 - precision: 0.9037 - recall: 0.8577 - val_loss: 1833.3494 - val_ACL5: 1833.3494 - val_binary_crossentropy_plus_jaccard_loss: 0.4590 - val_dice_loss: 0.2204 - val_iou_coeff: 0.6748 - val_precision: 0.7821 - val_recall: 0.7193\n\nEpoch 00021: val_dice_loss did not improve from 0.20387\nEpoch 22/40\n1912/1912 [==============================] - 184s 96ms/step - loss: 2347.2115 - ACL5: 2347.2115 - binary_crossentropy_plus_jaccard_loss: 0.2562 - dice_loss: 0.1147 - iou_coeff: 0.7988 - precision: 0.9095 - recall: 0.8657 - val_loss: 1969.2870 - val_ACL5: 1969.2870 - val_binary_crossentropy_plus_jaccard_loss: 0.5118 - val_dice_loss: 0.2838 - val_iou_coeff: 0.6152 - val_precision: 0.7713 - val_recall: 0.6580\n\nEpoch 00022: val_dice_loss did not improve from 0.20387\nEpoch 23/40\n1912/1912 [==============================] - 184s 96ms/step - loss: 2286.9648 - ACL5: 2286.9648 - binary_crossentropy_plus_jaccard_loss: 0.2524 - dice_loss: 0.1122 - iou_coeff: 0.8028 - precision: 0.9091 - recall: 0.8679 - val_loss: 2012.2617 - val_ACL5: 2012.2617 - val_binary_crossentropy_plus_jaccard_loss: 0.5062 - val_dice_loss: 0.2681 - val_iou_coeff: 0.6277 - val_precision: 0.7670 - val_recall: 0.6602\n\nEpoch 00023: val_dice_loss did not improve from 0.20387\nEpoch 24/40\n1912/1912 [==============================] - 183s 96ms/step - loss: 2304.7051 - ACL5: 2304.7051 - binary_crossentropy_plus_jaccard_loss: 0.2509 - dice_loss: 0.1114 - iou_coeff: 0.8040 - precision: 0.9085 - recall: 0.8700 - val_loss: 1706.6018 - val_ACL5: 1706.6018 - val_binary_crossentropy_plus_jaccard_loss: 0.4355 - val_dice_loss: 0.1962 - val_iou_coeff: 0.6984 - val_precision: 0.8188 - val_recall: 0.7308\n\nEpoch 00024: val_dice_loss improved from 0.20387 to 0.19618, saving model to Res2Net.hdf5\nEpoch 25/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 2229.6093 - ACL5: 2229.6093 - binary_crossentropy_plus_jaccard_loss: 0.2451 - dice_loss: 0.1083 - iou_coeff: 0.8086 - precision: 0.9128 - recall: 0.8715 - val_loss: 1826.9797 - val_ACL5: 1826.9797 - val_binary_crossentropy_plus_jaccard_loss: 0.4810 - val_dice_loss: 0.2290 - val_iou_coeff: 0.6665 - val_precision: 0.8111 - val_recall: 0.6775\n\nEpoch 00025: val_dice_loss did not improve from 0.19618\nEpoch 26/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 2215.1965 - ACL5: 2215.1965 - binary_crossentropy_plus_jaccard_loss: 0.2426 - dice_loss: 0.1063 - iou_coeff: 0.8117 - precision: 0.9157 - recall: 0.8746 - val_loss: 1980.4891 - val_ACL5: 1980.4891 - val_binary_crossentropy_plus_jaccard_loss: 0.4931 - val_dice_loss: 0.2707 - val_iou_coeff: 0.6271 - val_precision: 0.7843 - val_recall: 0.6803\n\nEpoch 00026: val_dice_loss did not improve from 0.19618\nEpoch 27/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 2168.2222 - ACL5: 2168.2222 - binary_crossentropy_plus_jaccard_loss: 0.2376 - dice_loss: 0.1046 - iou_coeff: 0.8138 - precision: 0.9163 - recall: 0.8777 - val_loss: 2014.4412 - val_ACL5: 2014.4412 - val_binary_crossentropy_plus_jaccard_loss: 0.5140 - val_dice_loss: 0.2739 - val_iou_coeff: 0.6221 - val_precision: 0.7783 - val_recall: 0.6574\n\nEpoch 00027: val_dice_loss did not improve from 0.19618\nEpoch 28/40\n1912/1912 [==============================] - 183s 96ms/step - loss: 2164.0442 - ACL5: 2164.0442 - binary_crossentropy_plus_jaccard_loss: 0.2356 - dice_loss: 0.1036 - iou_coeff: 0.8167 - precision: 0.9155 - recall: 0.8768 - val_loss: 1729.7151 - val_ACL5: 1729.7151 - val_binary_crossentropy_plus_jaccard_loss: 0.4305 - val_dice_loss: 0.2078 - val_iou_coeff: 0.6879 - val_precision: 0.8101 - val_recall: 0.7491\n\nEpoch 00028: val_dice_loss did not improve from 0.19618\nEpoch 29/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 2138.7433 - ACL5: 2138.7433 - binary_crossentropy_plus_jaccard_loss: 0.2297 - dice_loss: 0.1007 - iou_coeff: 0.8201 - precision: 0.9200 - recall: 0.8824 - val_loss: 1907.9490 - val_ACL5: 1907.9490 - val_binary_crossentropy_plus_jaccard_loss: 0.4914 - val_dice_loss: 0.2437 - val_iou_coeff: 0.6500 - val_precision: 0.7886 - val_recall: 0.6705\n\nEpoch 00029: val_dice_loss did not improve from 0.19618\nEpoch 30/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 2078.0543 - ACL5: 2078.0543 - binary_crossentropy_plus_jaccard_loss: 0.2258 - dice_loss: 0.0986 - iou_coeff: 0.8240 - precision: 0.9193 - recall: 0.8840 - val_loss: 1775.5817 - val_ACL5: 1775.5817 - val_binary_crossentropy_plus_jaccard_loss: 0.4406 - val_dice_loss: 0.2153 - val_iou_coeff: 0.6827 - val_precision: 0.7791 - val_recall: 0.7500\n\nEpoch 00030: val_dice_loss did not improve from 0.19618\nEpoch 31/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 2067.3931 - ACL5: 2067.3931 - binary_crossentropy_plus_jaccard_loss: 0.2258 - dice_loss: 0.0964 - iou_coeff: 0.8273 - precision: 0.9166 - recall: 0.8835 - val_loss: 1929.2222 - val_ACL5: 1929.2222 - val_binary_crossentropy_plus_jaccard_loss: 0.4838 - val_dice_loss: 0.2607 - val_iou_coeff: 0.6361 - val_precision: 0.7952 - val_recall: 0.6880\n\nEpoch 00031: val_dice_loss did not improve from 0.19618\nEpoch 32/40\n1912/1912 [==============================] - 183s 96ms/step - loss: 2048.9607 - ACL5: 2048.9607 - binary_crossentropy_plus_jaccard_loss: 0.2203 - dice_loss: 0.0954 - iou_coeff: 0.8286 - precision: 0.9205 - recall: 0.8885 - val_loss: 1935.2568 - val_ACL5: 1935.2568 - val_binary_crossentropy_plus_jaccard_loss: 0.4816 - val_dice_loss: 0.2324 - val_iou_coeff: 0.6566 - val_precision: 0.8199 - val_recall: 0.6895\n\nEpoch 00032: val_dice_loss did not improve from 0.19618\nEpoch 33/40\n1912/1912 [==============================] - 184s 96ms/step - loss: 2043.2355 - ACL5: 2043.2355 - binary_crossentropy_plus_jaccard_loss: 0.2219 - dice_loss: 0.0964 - iou_coeff: 0.8276 - precision: 0.9199 - recall: 0.8866 - val_loss: 1980.8108 - val_ACL5: 1980.8108 - val_binary_crossentropy_plus_jaccard_loss: 0.4833 - val_dice_loss: 0.2479 - val_iou_coeff: 0.6397 - val_precision: 0.8270 - val_recall: 0.6859\n\nEpoch 00033: val_dice_loss did not improve from 0.19618\nEpoch 34/40\n1912/1912 [==============================] - 183s 96ms/step - loss: 2017.9586 - ACL5: 2017.9586 - binary_crossentropy_plus_jaccard_loss: 0.2185 - dice_loss: 0.0948 - iou_coeff: 0.8312 - precision: 0.9217 - recall: 0.8858 - val_loss: 1929.0525 - val_ACL5: 1929.0525 - val_binary_crossentropy_plus_jaccard_loss: 0.4877 - val_dice_loss: 0.2497 - val_iou_coeff: 0.6471 - val_precision: 0.7762 - val_recall: 0.6816\n\nEpoch 00034: val_dice_loss did not improve from 0.19618\nEpoch 35/40\n1912/1912 [==============================] - 185s 97ms/step - loss: 2009.3989 - ACL5: 2009.3989 - binary_crossentropy_plus_jaccard_loss: 0.2156 - dice_loss: 0.0929 - iou_coeff: 0.8331 - precision: 0.9237 - recall: 0.8881 - val_loss: 1816.9670 - val_ACL5: 1816.9670 - val_binary_crossentropy_plus_jaccard_loss: 0.4399 - val_dice_loss: 0.2161 - val_iou_coeff: 0.6781 - val_precision: 0.7799 - val_recall: 0.7653\n\nEpoch 00035: val_dice_loss did not improve from 0.19618\nEpoch 36/40\n1912/1912 [==============================] - 186s 97ms/step - loss: 2012.4725 - ACL5: 2012.4725 - binary_crossentropy_plus_jaccard_loss: 0.2168 - dice_loss: 0.0938 - iou_coeff: 0.8325 - precision: 0.9218 - recall: 0.8876 - val_loss: 1698.8550 - val_ACL5: 1698.8550 - val_binary_crossentropy_plus_jaccard_loss: 0.4370 - val_dice_loss: 0.2049 - val_iou_coeff: 0.6924 - val_precision: 0.8050 - val_recall: 0.7423\n\nEpoch 00036: val_dice_loss did not improve from 0.19618\nEpoch 37/40\n1912/1912 [==============================] - 184s 96ms/step - loss: 1923.0788 - ACL5: 1923.0788 - binary_crossentropy_plus_jaccard_loss: 0.2046 - dice_loss: 0.0885 - iou_coeff: 0.8405 - precision: 0.9256 - recall: 0.8956 - val_loss: 1878.7979 - val_ACL5: 1878.7979 - val_binary_crossentropy_plus_jaccard_loss: 0.4760 - val_dice_loss: 0.2188 - val_iou_coeff: 0.6763 - val_precision: 0.8017 - val_recall: 0.7114\n\nEpoch 00037: val_dice_loss did not improve from 0.19618\nEpoch 38/40\n1912/1912 [==============================] - 184s 96ms/step - loss: 1978.8746 - ACL5: 1978.8746 - binary_crossentropy_plus_jaccard_loss: 0.2129 - dice_loss: 0.0922 - iou_coeff: 0.8359 - precision: 0.9250 - recall: 0.8917 - val_loss: 1787.9810 - val_ACL5: 1787.9810 - val_binary_crossentropy_plus_jaccard_loss: 0.4492 - val_dice_loss: 0.2085 - val_iou_coeff: 0.6838 - val_precision: 0.8195 - val_recall: 0.7234\n\nEpoch 00038: val_dice_loss did not improve from 0.19618\nEpoch 39/40\n1912/1912 [==============================] - 183s 96ms/step - loss: 1929.1946 - ACL5: 1929.1946 - binary_crossentropy_plus_jaccard_loss: 0.2068 - dice_loss: 0.0907 - iou_coeff: 0.8388 - precision: 0.9241 - recall: 0.8937 - val_loss: 2021.2061 - val_ACL5: 2021.2061 - val_binary_crossentropy_plus_jaccard_loss: 0.5298 - val_dice_loss: 0.2964 - val_iou_coeff: 0.5982 - val_precision: 0.8013 - val_recall: 0.6165\n\nEpoch 00039: val_dice_loss did not improve from 0.19618\nEpoch 40/40\n1912/1912 [==============================] - 182s 95ms/step - loss: 1914.7765 - ACL5: 1914.7765 - binary_crossentropy_plus_jaccard_loss: 0.2027 - dice_loss: 0.0862 - iou_coeff: 0.8440 - precision: 0.9268 - recall: 0.8967 - val_loss: 1859.5663 - val_ACL5: 1859.5663 - val_binary_crossentropy_plus_jaccard_loss: 0.4739 - val_dice_loss: 0.2196 - val_iou_coeff: 0.6772 - val_precision: 0.7851 - val_recall: 0.7301\n\nEpoch 00040: val_dice_loss did not improve from 0.19618\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR7LOc44jXro"
      },
      "source": [
        "# DeepLabV3 on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y84NzOdzjXrp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T13:04:16.594193Z",
          "iopub.execute_input": "2021-09-14T13:04:16.594572Z",
          "iopub.status.idle": "2021-09-14T13:04:16.600251Z",
          "shell.execute_reply.started": "2021-09-14T13:04:16.594528Z",
          "shell.execute_reply": "2021-09-14T13:04:16.599327Z"
        },
        "trusted": true,
        "id": "9zuUHlYwjXrs"
      },
      "source": [
        "test_path = '../input/testdata/Test'\n",
        "test_image_folder =\"images\"\n",
        "Test_path = test_path + '/' + 'test_image_folder'\n",
        "test_label_folder =\"label\"\n",
        "\n",
        "\n",
        "import os\n",
        "  \n",
        "# Directory\n",
        "directory = \"RESULT_DeepLabV3_Plus\"\n",
        "  \n",
        "# Parent Directory path\n",
        "parent_dir = \"./\"\n",
        "  \n",
        "# Path\n",
        "path = os.path.join(parent_dir, directory)\n",
        "os.mkdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T13:05:44.420783Z",
          "iopub.execute_input": "2021-09-14T13:05:44.421130Z",
          "iopub.status.idle": "2021-09-14T13:06:02.889476Z",
          "shell.execute_reply.started": "2021-09-14T13:05:44.421100Z",
          "shell.execute_reply": "2021-09-14T13:06:02.887622Z"
        },
        "trusted": true,
        "id": "JcROpUrFjXrs",
        "outputId": "e2364a58-083a-4e93-8e00-6690beee2c1c"
      },
      "source": [
        "from tqdm import tqdm\n",
        "  \n",
        "# Path\n",
        "#path = os.path.join(parent_dir, directory)\n",
        "#os.mkdir(path)\n",
        "\n",
        "\n",
        "def read_image(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (256, 256))\n",
        "    x = x/255.0\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    x = cv2.resize(x, ( 256 , 256))\n",
        "    x = np.expand_dims(x, axis=-1)\n",
        "    return x\n",
        "\n",
        "def mask_parse(mask):\n",
        "    mask = np.squeeze(mask)\n",
        "    mask = [mask, mask, mask]\n",
        "    mask = np.transpose(mask, (1, 2, 0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def tf_parse(imagepath , maskpath):\n",
        "  def _parse(imagepath , maskpath):\n",
        "    x = read_image(imagepath)\n",
        "    y = read_mask(maskpath)\n",
        "\n",
        "    return x , y\n",
        "\n",
        "  x , y = tf.numpy_function(_parse , [imagepath , maskpath] , [tf.float64 , tf.float64] )\n",
        "  x.set_shape([256 , 256 , 3])\n",
        "  y.set_shape([256, 256, 1])\n",
        "\n",
        "  return x , y \n",
        "\n",
        "\n",
        "def tf_dataset( imagepath , maskpath , batch = 2):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((imagepath , maskpath))\n",
        "  dataset = dataset.map(tf_parse)\n",
        "  dataset = dataset.batch(batch)\n",
        "  dataset = dataset.repeat()\n",
        "  return dataset\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ## Dataset\n",
        "    \n",
        "    batch_size = 8\n",
        "    #(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(\"/content/drive/MyDrive/Test\")\n",
        "    test_x = os.listdir(os.path.join(test_path ,test_image_folder ))\n",
        "    test_y = os.listdir(os.path.join(test_path ,test_label_folder ))\n",
        "    \n",
        "    TEST_X = []\n",
        "    TEST_Y = []\n",
        "    for img_file_name in test_x:\n",
        "        TEST_X.append('../input/testdata/Test/images' + \"/\" +img_file_name)\n",
        "        \n",
        "    for label_file_name in test_y:\n",
        "        TEST_Y.append('../input/testdata/Test/label'+ \"/\" +label_file_name)\n",
        "    test_dataset = tf_dataset( TEST_X , TEST_Y, batch=batch_size)\n",
        "\n",
        "    test_steps = (len(TEST_X)//batch_size)\n",
        "    if len(TEST_X) % batch_size != 0:\n",
        "        test_steps += 1\n",
        "\n",
        "    #with CustomObjectScope({'iou': iou}):\n",
        "    #    model = tf.keras.models.load_model(\"/content/drive/model.h5\")\n",
        "\n",
        "    #model.evaluate(test_dataset, steps=test_steps)\n",
        "    model.load_weights(\"./Res2Net.hdf5\")\n",
        "    for i, (x, y) in tqdm(enumerate(zip(TEST_X, TEST_Y)), total=len(TEST_X)):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        y_pred = model.predict(np.expand_dims(x, axis=0))[0] > 0.5\n",
        "        h, w, _ = x.shape\n",
        "        white_line = np.ones((h, 10, 3)) * 255.0\n",
        "\n",
        "        all_images = [\n",
        "            x * 255.0, white_line,\n",
        "            mask_parse(y), white_line,\n",
        "            mask_parse(y_pred) * 255.0\n",
        "        ]\n",
        "        image = np.concatenate(all_images, axis=1)\n",
        "        \n",
        "        cv2.imwrite(f\"./RESULT_DeepLabV3_Plus/{i}.png\", image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 200/200 [00:17<00:00, 11.17it/s]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T13:13:08.813838Z",
          "iopub.execute_input": "2021-09-14T13:13:08.814180Z",
          "iopub.status.idle": "2021-09-14T13:13:09.578411Z",
          "shell.execute_reply.started": "2021-09-14T13:13:08.814144Z",
          "shell.execute_reply": "2021-09-14T13:13:09.577418Z"
        },
        "trusted": true,
        "id": "bYd43FdDjXrt",
        "outputId": "2771ab44-fe22-40fb-baff-4b674f4b1312"
      },
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"RESULT_DeepLabV3_Plus\", 'zip', \"./RESULT_DeepLabV3_Plus\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/kaggle/working/RESULT_DeepLabV3_Plus.zip'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-14T13:23:25.662955Z",
          "iopub.execute_input": "2021-09-14T13:23:25.663273Z",
          "iopub.status.idle": "2021-09-14T13:23:25.669295Z",
          "shell.execute_reply.started": "2021-09-14T13:23:25.663243Z",
          "shell.execute_reply": "2021-09-14T13:23:25.668298Z"
        },
        "trusted": true,
        "id": "hjfMb9BnjXrt",
        "outputId": "69b96855-6e0e-42f1-f143-e37f10197229"
      },
      "source": [
        "os.chdir(r'/kaggle/working')\n",
        "from IPython.display import FileLink\n",
        "\n",
        "FileLink(r'./RESULT_DeepLabV3_Plus.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 35,
          "output_type": "execute_result",
          "data": {
            "text/plain": "/kaggle/working/RESULT_DeepLabV3_Plus.zip",
            "text/html": "<a href='./RESULT_DeepLabV3_Plus.zip' target='_blank'>./RESULT_DeepLabV3_Plus.zip</a><br>"
          },
          "metadata": {}
        }
      ]
    }
  ]
}